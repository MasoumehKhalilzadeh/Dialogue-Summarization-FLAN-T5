{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Step 1: Install Required Libraries\n",
        "\n",
        "What this does: It brings in the tools (libraries) that help us read stories (dialogues) and tell what they mean (summarize)."
      ],
      "metadata": {
        "id": "FfwiDIcVZOKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYY_neXRZ-Pf",
        "outputId": "f02c98ef-e570-43f6-9e9d-792e0c4d37f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the DailyDialog Dataset\n",
        "\n",
        "Now let’s go to the Hugging Face library and grab the DailyDialog book full of short chats.\n"
      ],
      "metadata": {
        "id": "FGnRkTOmaDj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load from Hugging Face\n",
        "dataset = load_dataset(\"daily_dialog\")\n",
        "\n",
        "# Show one sample\n",
        "print(dataset[\"test\"][3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AUcs1uraEc1",
        "outputId": "db089373-bb8e-4117-b1a7-148bb6cc98c1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dialog': ['Believe it or not , tea is the most popular beverage in the world after water . ', ' Well , people from Asia to Europe all enjoy tea . ', ' Right . And China is the homeland of tea . ', \" Yes , Chinese people love drinking tea so much . Some even claim they can't live without tea . \", ' Do you know there are several catagories of Chinese tea ? ', ' Yes , I believe there are green teas , black teas and scented teas . Any Others ? ', ' Well , have you ever heard of Oulong tea and compressed tea ? ', \" Oh , yeah . Oulong tea is good for one's health . isn't it ? \", ' You surely know a lot about Chinese tea . ', ' Sure , I like drinking tea at teahouses . ', ' Oh , so do I . ', \" Why don't we go for one now ? \", ' Great . We can chat while enjoying a cup there . ', \" Let's go ! \"], 'act': [1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 3, 4, 3], 'emotion': [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 4]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Format the Dialogue\n",
        "\n",
        "The dialogue is like puzzle pieces. We want to make it look like a real conversation with Speaker 1 and Speaker 2."
      ],
      "metadata": {
        "id": "XNzR4SBDagSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dialogue(dialogue_lines):\n",
        "    return \"\\n\".join([f\"Speaker {i % 2 + 1}: {line}\" for i, line in enumerate(dialogue_lines)])\n",
        "\n",
        "# Use one example\n",
        "sample_dialogue = format_dialogue(dataset[\"test\"][3][\"dialog\"])\n",
        "print(sample_dialogue)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oghET7cjag88",
        "outputId": "67c8e84d-ed2b-42f5-a7a0-4855689c3203"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker 1: Believe it or not , tea is the most popular beverage in the world after water . \n",
            "Speaker 2:  Well , people from Asia to Europe all enjoy tea . \n",
            "Speaker 1:  Right . And China is the homeland of tea . \n",
            "Speaker 2:  Yes , Chinese people love drinking tea so much . Some even claim they can't live without tea . \n",
            "Speaker 1:  Do you know there are several catagories of Chinese tea ? \n",
            "Speaker 2:  Yes , I believe there are green teas , black teas and scented teas . Any Others ? \n",
            "Speaker 1:  Well , have you ever heard of Oulong tea and compressed tea ? \n",
            "Speaker 2:  Oh , yeah . Oulong tea is good for one's health . isn't it ? \n",
            "Speaker 1:  You surely know a lot about Chinese tea . \n",
            "Speaker 2:  Sure , I like drinking tea at teahouses . \n",
            "Speaker 1:  Oh , so do I . \n",
            "Speaker 2:  Why don't we go for one now ? \n",
            "Speaker 1:  Great . We can chat while enjoying a cup there . \n",
            "Speaker 2:  Let's go ! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Prompt Templates (Zero, One, Few-Shot)\n",
        "\n",
        "Just like asking a smart robot:\n",
        "\"Hey, can you tell me what this chat is about in a few words?\"\n",
        "\n",
        "We write different ways to ask it (these are called “prompts”):\n",
        "\n",
        "What this does: It simply asks, “Please summarize this!”\n",
        "\n",
        "We also have smarter ways, where we show examples first. That’s called one-shot and few-shot — like giving the robot a few warm-up questions."
      ],
      "metadata": {
        "id": "KmrgARZiasc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_shot_prompt(dialogue):\n",
        "    return f\"Summarize this conversation:\\n{dialogue}\"\n",
        "\n",
        "def one_shot_prompt(dialogue):\n",
        "    example = (\n",
        "        \"Summarize this conversation:\\n\"\n",
        "        \"Speaker 1: I lost my phone.\\n\"\n",
        "        \"Speaker 2: Did you try calling it?\\n\"\n",
        "        \"Speaker 1: Yes, but it's not ringing.\\n\"\n",
        "        \"Speaker 2: Maybe it's on silent.\\n\"\n",
        "        \"Summary: A person lost their phone and tried calling it, but it might be on silent.\\n\\n\"\n",
        "    )\n",
        "    return example + f\"Conversation:\\n{dialogue}\\nSummary:\"\n",
        "\n",
        "def few_shot_prompt(dialogue):\n",
        "    examples = (\n",
        "        \"Summarize this conversation:\\n\"\n",
        "        \"Speaker 1: I'm going to the gym.\\n\"\n",
        "        \"Speaker 2: That's great! Stay fit!\\n\"\n",
        "        \"Summary: A person is planning to go to the gym.\\n\\n\"\n",
        "        \"Speaker 1: I feel sick today.\\n\"\n",
        "        \"Speaker 2: You should rest.\\n\"\n",
        "        \"Summary: One person feels sick and is advised to rest.\\n\\n\"\n",
        "    )\n",
        "    return examples + f\"Conversation:\\n{dialogue}\\nSummary:\"\n"
      ],
      "metadata": {
        "id": "j5sZUjf2atQu"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Load flan-t5-base Model\n",
        "\n",
        "We now bring in the robot (the FLAN-T5 model), so it can read and understand."
      ],
      "metadata": {
        "id": "GZvZCtcwa0wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "iwOrPKona1VN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Run Summarization\n",
        "\n",
        "Now we send the chat to the robot, and it gives us a short summary.\n",
        "\n",
        "What this does: Converts our question into robot language → asks the robot → then changes the answer back into normal words"
      ],
      "metadata": {
        "id": "p0XAg8mnbi-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_summary(prompt, max_length=100):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_length=max_length)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "GauP5u6LbjZY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Generate All 3 Types of Summaries"
      ],
      "metadata": {
        "id": "rupMEOCebnLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the dialogue\n",
        "dialogue_text = format_dialogue(dataset[\"test\"][3][\"dialog\"])\n",
        "\n",
        "# Zero-shot\n",
        "zs_prompt = zero_shot_prompt(dialogue_text)\n",
        "zs_summary = generate_summary(zs_prompt)\n",
        "\n",
        "# One-shot\n",
        "os_prompt = one_shot_prompt(dialogue_text)\n",
        "os_summary = generate_summary(os_prompt)\n",
        "\n",
        "# Few-shot\n",
        "fs_prompt = few_shot_prompt(dialogue_text)\n",
        "fs_summary = generate_summary(fs_prompt)\n",
        "\n",
        "# Display\n",
        "print(\"🧊 Zero-Shot Summary:\\n\", zs_summary)\n",
        "print(\"\\n🎯 One-Shot Summary:\\n\", os_summary)\n",
        "print(\"\\n🔥 Few-Shot Summary:\\n\", fs_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Dy7wHpbnnY",
        "outputId": "327b3954-cde1-4268-d425-8ff8e478dbae"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧊 Zero-Shot Summary:\n",
            " We will go to teahouses .\n",
            "\n",
            "🎯 One-Shot Summary:\n",
            " People from Asia to Europe all enjoy tea .\n",
            "\n",
            "🔥 Few-Shot Summary:\n",
            " People from Asia to Europe all enjoy tea .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🧊 Zero-Shot: The robot is just told to summarize with no help.\n",
        "\n",
        "🎯 One-Shot: You show one example first.\n",
        "\n",
        "🔥 Few-Shot: You show two or three examples so it understands better."
      ],
      "metadata": {
        "id": "W2-X1exGeZcu"
      }
    }
  ]
}